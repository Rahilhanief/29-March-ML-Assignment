{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b031a359-7823-45a8-899d-23ab6d27e6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLasso regression is a regularization technique. \\nIt is used over regression methods for a more accurate prediction. This model uses shrinkage. \\nShrinkage is where data values are shrunk towards a central point as the mean.\\n\\nLasso method overcomes the disadvantage of Ridge regression by not only punishing high values of the coefficients β\\nbut actually setting them to zero if they are not relevant.\\nTherefore, you might end up with fewer features included in the model than you started with, which is a huge advantage.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No.1 :\n",
    "\"\"\"\n",
    "Lasso regression is a regularization technique. \n",
    "It is used over regression methods for a more accurate prediction. This model uses shrinkage. \n",
    "Shrinkage is where data values are shrunk towards a central point as the mean.\n",
    "\n",
    "Lasso method overcomes the disadvantage of Ridge regression by not only punishing high values of the coefficients β\n",
    "but actually setting them to zero if they are not relevant.\n",
    "Therefore, you might end up with fewer features included in the model than you started with, which is a huge advantage.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce64339a-fb1a-4395-8a81-b30d424bb35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe main advantage of a LASSO regression model is that it has the ability to set the coefficients\\nfor features it does not consider interesting to zero. \\nThis means that the model does some automatic feature selection to decide which features should and\\nshould not be included on its own.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No.2 :\n",
    "'''\n",
    "The main advantage of a LASSO regression model is that it has the ability to set the coefficients\n",
    "for features it does not consider interesting to zero. \n",
    "This means that the model does some automatic feature selection to decide which features should and\n",
    "should not be included on its own.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44b5c63-5151-4696-8407-adfce1c91f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The estimated coefficients target the same targets, and both have some estimation error \\n(which, if squared, can be decomposed into bias and variance), so in this sense their interpretation is the same.\\nNow of course the methods are not the same, so you get different estimated coefficient values.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No.3 :\n",
    "\"\"\"The estimated coefficients target the same targets, and both have some estimation error \n",
    "(which, if squared, can be decomposed into bias and variance), so in this sense their interpretation is the same.\n",
    "Now of course the methods are not the same, so you get different estimated coefficient values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a79da4a3-5459-4e61-b09c-e53d888470f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A tuning parameter (λ), sometimes called a penalty parameter, controls the strength of the penalty \\nterm in ridge regression and lasso regression. \\nIt is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No.4 :\n",
    "\"\"\"A tuning parameter (λ), sometimes called a penalty parameter, controls the strength of the penalty \n",
    "term in ridge regression and lasso regression. \n",
    "It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7407e9-a112-4c0d-8b7a-119b7543d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRegularization with a lasso penalty is an advantageous in that it estimates some coefficients in \\nlinear regression models to be exactly zero. \\nWe propose imposing a weighted lasso penalty on a nonlinear regression model and thereby selecting \\nthe number of basis functions effectively.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 5 :\n",
    "\"\"\"\n",
    "Regularization with a lasso penalty is an advantageous in that it estimates some coefficients in \n",
    "linear regression models to be exactly zero. \n",
    "We propose imposing a weighted lasso penalty on a nonlinear regression model and thereby selecting \n",
    "the number of basis functions effectively.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a4590e-949f-4543-8bb3-e69ea21275c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSimilar to the lasso regression, ridge regression puts a similar constraint on the coefficients by\\nintroducing a penalty factor.\\nHowever, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square.\\n\\nRidge regression is also referred to as L2 Regularization.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"\n",
    "Similar to the lasso regression, ridge regression puts a similar constraint on the coefficients by\n",
    "introducing a penalty factor.\n",
    "However, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square.\n",
    "\n",
    "Ridge regression is also referred to as L2 Regularization.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92078768-9464-459a-abd9-7c23aa130f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLasso regression is a linear regression technique with L1 prior as a regularize. \\nThe idea is to reduce the multicollinearity by regularization by reducing the coefficients of\\nthe feature that are multicollinear.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 7 :\n",
    "\"\"\"\n",
    "Lasso regression is a linear regression technique with L1 prior as a regularize. \n",
    "The idea is to reduce the multicollinearity by regularization by reducing the coefficients of\n",
    "the feature that are multicollinear.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "523a7744-db39-4de6-bcf0-e1d4057f7f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLasso regression can be used for automatic feature selection, as the geometry of its constrained\\nregion allows coefficient values to inert to zero.\\nAn alpha value of zero in either ridge or lasso model will have results similar to the regression model.\\nThe larger the alpha value, the more aggressive the penalization.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 8 :\n",
    "'''\n",
    "Lasso regression can be used for automatic feature selection, as the geometry of its constrained\n",
    "region allows coefficient values to inert to zero.\n",
    "An alpha value of zero in either ridge or lasso model will have results similar to the regression model.\n",
    "The larger the alpha value, the more aggressive the penalization.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
